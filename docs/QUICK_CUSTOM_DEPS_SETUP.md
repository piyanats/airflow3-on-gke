# Quick Setup Guide: Custom Dependencies

## ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python Packages ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÅ‡∏ö‡∏ö‡∏î‡πà‡∏ß‡∏ô

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á Custom Docker Image (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) üöÄ

#### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏û‡∏¥‡πà‡∏° Dependencies

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `docker/requirements.txt`:

```txt
# ‡πÄ‡∏û‡∏¥‡πà‡∏° packages ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
pandas==2.1.4
google-cloud-storage==2.13.0
google-cloud-bigquery==3.14.0
requests==2.31.0
```

#### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: Build Image

```bash
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables
export GCP_PROJECT_ID="your-project-id"
export IMAGE_NAME="airflow-custom"
export IMAGE_TAG="3.0.0-v1"

# Build ‡πÅ‡∏•‡∏∞ push
./scripts/build-custom-image.sh
```

Script ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:
- Build Docker image
- Test imports
- Push to Google Container Registry
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå values.yaml ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á

#### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: Deploy

```bash
helm upgrade --install airflow ./airflow-helm \
    -f examples/values-custom-image.yaml
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ Init Container (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Testing)

‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö packages ‡∏Å‡πà‡∏≠‡∏ô build image

```yaml
# values.yaml
airflow:
  extraInitContainers:
    - name: install-deps
      image: apache/airflow:3.0.0-python3.11
      command:
        - bash
        - -c
        - |
          pip install --user \
            pandas==2.1.4 \
            google-cloud-storage==2.13.0
      volumeMounts:
        - name: dependencies
          mountPath: /home/airflow/.local

  extraVolumes:
    - name: dependencies
      emptyDir: {}

  extraVolumeMounts:
    - name: dependencies
      mountPath: /home/airflow/.local
```

‚ö†Ô∏è **‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î:**
- ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ (‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà pod restart)
- ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: requirements.txt ‡∏à‡∏≤‡∏Å Git Repository

#### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏û‡∏¥‡πà‡∏° requirements.txt ‡πÉ‡∏ô DAGs repo

```
your-dags-repo/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ my_dag.py
‚îî‚îÄ‚îÄ requirements.txt
```

#### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: Configure Airflow

```yaml
# values.yaml
airflow:
  extraInitContainers:
    - name: install-requirements
      image: apache/airflow:3.0.0-python3.11
      command:
        - bash
        - -c
        - |
          if [ -f /dags/requirements.txt ]; then
            pip install --user -r /dags/requirements.txt
          fi
      volumeMounts:
        - name: dags
          mountPath: /dags
        - name: deps
          mountPath: /home/airflow/.local

  extraVolumes:
    - name: deps
      emptyDir: {}

  extraVolumeMounts:
    - name: deps
      mountPath: /home/airflow/.local

dags:
  gitSync:
    enabled: true
    repo: "https://github.com/your-org/airflow-dags.git"
```

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Dependencies ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Google Cloud Platform

```txt
google-cloud-storage==2.13.0
google-cloud-bigquery==3.14.0
google-cloud-pubsub==2.19.0
db-dtypes==1.1.1
```

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Processing

```txt
pandas==2.1.4
numpy==1.26.2
pyarrow==14.0.1
polars==0.20.2
```

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AWS

```txt
boto3==1.34.8
s3fs==2023.12.2
awswrangler==3.5.1
```

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning

```txt
scikit-learn==1.3.2
tensorflow==2.15.0
torch==2.1.2
mlflow==2.9.2
```

## Build ‡πÅ‡∏ö‡∏ö Manual

```bash
# 1. Build image
cd docker/
docker build -t gcr.io/PROJECT_ID/airflow-custom:v1 .

# 2. Test locally
docker run --rm gcr.io/PROJECT_ID/airflow-custom:v1 \
    python -c "import pandas; print(pandas.__version__)"

# 3. Configure Docker
gcloud auth configure-docker

# 4. Push
docker push gcr.io/PROJECT_ID/airflow-custom:v1

# 5. Update values.yaml
# airflow:
#   image:
#     repository: gcr.io/PROJECT_ID/airflow-custom
#     tag: "v1"

# 6. Deploy
helm upgrade --install airflow ./airflow-helm -f values.yaml
```

## ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Dockerfile

‡∏°‡∏µ 3 ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:

### 1. Dockerfile (Standard)
```bash
docker build -f docker/Dockerfile .
```
- ‡∏°‡∏µ system dependencies (gcc, build tools)
- ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ compile packages
- ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤

### 2. Dockerfile.slim
```bash
docker build -f docker/Dockerfile.slim .
```
- Python packages ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
- Build ‡πÄ‡∏£‡πá‡∏ß, ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å
- ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ system packages

### 3. Dockerfile.multi-stage
```bash
docker build -f docker/Dockerfile.multi-stage .
```
- Compile ‡πÉ‡∏ô builder stage
- Image ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production

## ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

```bash
# Test Python version
docker run --rm your-image python --version

# Test package imports
docker run --rm your-image \
    python -c "import pandas, numpy; print('OK')"

# Test pip check
docker run --rm your-image pip check

# Interactive shell
docker run -it --rm your-image bash
```

## Troubleshooting

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Build ‡∏ä‡πâ‡∏≤
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:** ‡πÉ‡∏ä‡πâ multi-stage build ‡∏´‡∏£‡∏∑‡∏≠ build cache

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Import error ‡∏´‡∏•‡∏±‡∏á deploy
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ package ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
kubectl exec -it deployment/airflow-webserver -- pip list | grep pandas

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python path
kubectl exec -it deployment/airflow-webserver -- python -c "import sys; print(sys.path)"
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Package conflicts
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
```bash
# Check conflicts
docker run --rm your-image pip check

# ‡πÉ‡∏ä‡πâ pip-compile
pip install pip-tools
pip-compile requirements.in
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Image ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- ‡πÉ‡∏ä‡πâ multi-stage build
- ‡∏•‡∏ö packages ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
- ‡πÉ‡∏ä‡πâ slim base image

## Best Practices

‚úÖ **DO:**
- Pin ‡∏ó‡∏∏‡∏Å version ‡πÉ‡∏ô requirements.txt
- ‡πÉ‡∏ä‡πâ multi-stage builds ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production
- Test image ‡∏Å‡πà‡∏≠‡∏ô deploy
- ‡πÉ‡∏ä‡πâ semantic versioning (v1, v2, v3)
- Scan vulnerabilities

‚ùå **DON'T:**
- ‡πÉ‡∏™‡πà DAGs ‡πÉ‡∏ô image (‡πÉ‡∏ä‡πâ Git-Sync ‡πÅ‡∏ó‡∏ô)
- ‡πÉ‡∏ä‡πâ `pip install` ‡πÉ‡∏ô DAGs
- Hardcode secrets ‡πÉ‡∏ô image
- ‡πÉ‡∏ä‡πâ `latest` tag ‡πÉ‡∏ô production

## Quick Reference

```bash
# Build
./scripts/build-custom-image.sh

# Build specific Dockerfile
export DOCKERFILE=docker/Dockerfile.slim
./scripts/build-custom-image.sh

# Use Artifact Registry instead of GCR
export REGISTRY_TYPE=artifact-registry
./scripts/build-custom-image.sh

# Skip push (local testing)
export PUSH_IMAGE=false
./scripts/build-custom-image.sh
```

## CI/CD Integration

### GitHub Actions
```yaml
name: Build Airflow Image
on:
  push:
    paths:
      - 'docker/**'
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - run: ./scripts/build-custom-image.sh
```

### Cloud Build
```bash
gcloud builds submit --config cloudbuild.yaml docker/
```

## ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- [Complete Guide](CUSTOM_DEPENDENCIES.md)
- [Dockerfile Examples](../docker/)
- [Airflow Docker Documentation](https://airflow.apache.org/docs/docker-stack/build.html)

## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production

1. ‚úÖ Pin all package versions
2. ‚úÖ Use multi-stage build
3. ‚úÖ Scan for vulnerabilities
4. ‚úÖ Test thoroughly
5. ‚úÖ Use semantic versioning
6. ‚úÖ Document custom packages
7. ‚úÖ Set up CI/CD for auto-build
